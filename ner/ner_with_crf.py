# -*- coding: utf-8 -*-
"""NER with CRF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VIpv0MXOf_Qq0Gs21GGq12dwzES9a471

**如何应用CRF解决NER，并且训练出的模型进行可视化**

载入数据
"""

import pandas as pd
import numpy as np


data = pd.read_csv("ner_dataset.csv",encoding = "latin1")
data = data.fillna(method = "ffill")
# data.tail(10)

words = list(set(data["Word"].values))
n_words = len(words)
# n_words

"""我们的数据中共有47959个句子，其中包含了35178个单词。 
现在来构建一个输出句子的构造器。
"""

class SentenceGetter(object):
  def __init__(self,data):
    self.n_sent = 0
    self.data = data
    self.empty = False
    agg_func = lambda s : [(w,p,t) for w,p,t in zip(s["Word"].values.tolist(),s["POS"].values.tolist(),s["Tag"].values.tolist())]
    self.grouped = self.data.groupby("Sentence #").apply(agg_func)
    self.sentences = [s for s in self.grouped]
  def get_next(self):
    try:
      s = self.sentences[self.n_sent]
      self.n_sent += 1
      return s
    except:
      self.empty = True
      return None

getter = SentenceGetter(data)
sent = getter.get_next()
print(sent)

"""获取所有句子"""

sentences = getter.sentences

"""为CRF添加特征，包括词汇本身特征以及前后文的特征"""

def word2features(sent,i):
  word = sent[i][0]
  postag = sent[i][1]

  features = {
      "bias": 1.0,
      "word.lower()": word.lower(),
      "word[-3:]": word[-3:],
      "word[2:]": word[2:],
      "word.isupper()": word.isupper(),
      "word.istitle()": word.istitle(),
      "word.isdigit()": word.isdigit(),
      "postag": postag,
      "postag[:2]": postag[:2]
  }
  if i > 0:
    word1 = sent[i-1][0]
    postag1 = sent[i-1][1]
    features.update({
      "-1:word.isupper()": word1.isupper(),
      "-1:word.istitle()": word1.istitle(),
      "-1:word.isdigit()": word1.isdigit(),
      "-1:postag": postag1,
      "-1:postag[:2]": postag1[:2]
    })
  else:
    features["BOS"] = True
  if i < len(sent) - 1:
    word1 = sent[i+1][0]
    postag1 = sent[i+1][1]
    features.update({
      "+1:word.isupper()": word1.isupper(),
      "+1:word.istitle()": word1.istitle(),
      "+1:word.isdigit()": word1.isdigit(),
      "+1:postag": postag1,
      "+1:postag[:2]": postag1[:2]
    })
  else:
    features["EOS"] = True

  # test_1 = features

  return features

def sent2features(sent):
  return [word2features(sent,i) for i in range(len(sent))]

def sent2labels(sent):
  return [label for _, _, label in sent]

def sent2tokens(sent):
  return [token for token, _, _ in sent]

print(sent2features(sentences[0]))

print(sent2labels(sentences[0]))

print(sent2tokens(sentences[0]))

"""获取所有输入（features）与输出(labels)"""

X = [sent2features(s) for s in sentences]
y = [sent2labels(s) for s in sentences]

"""应用sklearn-crfsuite构建CRF"""


from sklearn_crfsuite import CRF

crf = CRF(
    algorithm = "lbfgs",
    c1 = 0.1,
    c2 = 0.1,
    max_iterations = 100,
    all_possible_transitions = False
)

from sklearn.model_selection import cross_val_predict
from sklearn_crfsuite.metrics import flat_classification_report

pred = cross_val_predict(estimator=crf,X=X,y=y,cv=5)

report = flat_classification_report(y_pred=pred, y_true=y)
print(report)

crf.fit(X,y)

"""可视化tags间的转移分数以及各features的重要性"""

# !pip install eli5
import eli5

eli5.show_weights(crf,top=30)

"""通过增加c1增加L1正则化的力度，使features变稀疏"""

crf = CRF(algorithm='lbfgs',
          c1=10,
          c2=0.1,
          max_iterations=100,
          all_possible_transitions=False)

pred = cross_val_predict(estimator=crf, X=X, y=y, cv=5)
report = flat_classification_report(y_pred=pred, y_true=y)
print(report)

crf.fit(X, y)


eli5.show_weights(crf, top=30)

"""增加L1正则后，features减少，但是模型效果仍旧不错"""